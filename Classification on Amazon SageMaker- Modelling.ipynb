{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab6d2c0-7184-47fc-9c28-002755522861",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBoost using SageMaker\n",
    "\n",
    "## Classification on Amazon SageMaker\n",
    "\n",
    "Perform a classification task on the given dataset.<br>\n",
    "Using the features given, you will train a XGBoost decision tree model to predict a given person's salary (the `WAGP` column) - which will be categorized into multiple bins.<br>\n",
    "\n",
    "--- \n",
    "\n",
    "#### Tasks: \n",
    "\n",
    "- Perform Exploratory Data Analysis on the given dataset\n",
    "- Save preprocessed datasets to Amazon S3\n",
    "- Use the Amazon Sagemaker platform to train an XGBoost model\n",
    "- Evaluate the model on the test set using real-time inference\n",
    "- Perform hyperparameter tuning on the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6703741-2fc8-40a3-8c55-db91ef629620",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Get Amazon IAM execution role & instance region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6e75b-73f4-4fc0-9c36-37c9e3b2ac66",
   "metadata": {
    "tags": []
   },
   "source": [
    " Make sure to create an S3 bucket or re-use the ones from prior exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2d81c6-e7fb-4349-9e09-057087e82a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ALL YOUR IMPORTS HERE\n",
    "import os, sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adabfe90-f2ab-49be-8603-7e8cf136d132",
   "metadata": {},
   "source": [
    "Get and store the IAM executon role, SageMaker Session, instance region & the SageMaker client in the cell below.\n",
    "\n",
    "#### **Expected output:** Print the instance region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1245f5ac-a175-409a-8ad9-eb8aa112e7ae",
   "metadata": {
    "cell_id": "8281449d-df80-4172-aec1-abe6efd366e6",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Define IAM role- this will be necessary when defining your model\n",
    "iam_role = get_execution_role()\n",
    "\n",
    "# Set SageMaker session handle\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Set the region of the instance \n",
    "my_region = sess.boto_session.region_name\n",
    "\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f736bda-6969-4e4f-9321-3622c6cb4707",
   "metadata": {},
   "source": [
    "### 2. Read data using pandas and select features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f31502-744e-4cba-bb3e-c757f344e87c",
   "metadata": {},
   "source": [
    "#### Read data from the given s3 bucket path into a pandas dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d75d3a-fffe-4ac3-81e2-d9b085bae854",
   "metadata": {},
   "source": [
    "#### **Expected output**: First five rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7b0aa0-3271-4ecc-9e5a-b5b3c7b32f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket mgta466-w24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bucket = \"mgta466-w24\"\n",
    "prefix = \"data\"\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456ec3a-23e3-4160-9e7b-0cd9b822a67f",
   "metadata": {
    "cell_id": "03e7fd9d-1c99-47c0-83bc-4f3f892d328c",
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "file_path = \"s3://mgta466-w24/data/person_records_merged_discretized.csv.zip\"\n",
    "\n",
    "\n",
    "data_fname = \"s3://{}/{}/{}\".format(bucket, prefix ,\"person_records_merged_discretized.csv.zip\")\n",
    "val_df = pd.read_csv(data_fname)\n",
    "df=val_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bd52b-32e9-473b-aaf6-ca1c94702b64",
   "metadata": {},
   "source": [
    "### Description of Columns\n",
    "\n",
    "There are lots of columns in the original dataset. However, we'll only use the following columns whose descriptions are given below:\n",
    "\n",
    "WAGP_CAT - Discretized wages or salary income past 12 months\n",
    "\n",
    "AGEP -  Age\n",
    "\n",
    "COW - Class of worker\n",
    "\n",
    "JWMNP - Travel time to work\n",
    "\n",
    "JWTR - Means of transportation to work\n",
    "\n",
    "MAR - Marital status\n",
    "\n",
    "PERNP - Total person's earnings\n",
    "\n",
    "NWAV - Available for work\n",
    "\n",
    "NWLA - On layoff from work\n",
    "\n",
    "NWLK - Looking for work\n",
    "\n",
    "NWAB - Temporary absence from work\n",
    "\n",
    "SCHL - Educational attainment\n",
    "\n",
    "WKW - Weeks worked during past 12 months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d54bd-5ba7-47be-b3a4-0a97342fbcac",
   "metadata": {},
   "source": [
    "#### 2.2 Feature selection - Select the features in the columns listed above\n",
    "Note: Make sure `WAGP_CAT` column is the first column. XGBoost expects labels to be in the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291953a-b6bb-42fa-ac76-f8df22f70b42",
   "metadata": {},
   "source": [
    "#### **Expected output**: First five rows of the dataframe after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f40b8a-6d97-44dc-9ef0-c0542156a7d3",
   "metadata": {
    "cell_id": "73b7dada-57a2-4116-ad94-3e43095d70cf",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WAGP_CAT  AGEP  COW  JWMNP  JWTR  MAR    PERNP  NWAV  NWLA  NWLK  NWAB  \\\n",
      "0         0    19  NaN    NaN   NaN    5      0.0   5.0   2.0   2.0   2.0   \n",
      "1         1    55  1.0   30.0   1.0    1  52000.0   5.0   3.0   3.0   3.0   \n",
      "2         0    56  6.0    NaN  11.0    1  99000.0   5.0   3.0   3.0   3.0   \n",
      "3         0    21  NaN    NaN   NaN    5      0.0   5.0   2.0   2.0   2.0   \n",
      "4         0    21  NaN    NaN   NaN    5      0.0   5.0   2.0   2.0   2.0   \n",
      "\n",
      "   SCHL  WKW  \n",
      "0  19.0  NaN  \n",
      "1  20.0  1.0  \n",
      "2  16.0  1.0  \n",
      "3  19.0  NaN  \n",
      "4  19.0  NaN  \n"
     ]
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "# YOUR CODE HERE\n",
    "# Selecting only the specified columns\n",
    "selected_columns = ['WAGP_CAT', 'AGEP', 'COW', 'JWMNP', 'JWTR', 'MAR', 'PERNP', 'NWAV', 'NWLA', 'NWLK', 'NWAB', 'SCHL', 'WKW']\n",
    "df= df[selected_columns]\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf899f-8675-42e1-a7b3-4a6b234bec95",
   "metadata": {},
   "source": [
    "### 3. Data processing\n",
    "\n",
    "#### 3.1 Remove highly correlated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6851ec41-e70e-4164-a596-5deeefc2f05a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAGP_CAT    1.000000\n",
       "AGEP       -0.023210\n",
       "COW        -0.044870\n",
       "JWMNP       0.121411\n",
       "JWTR       -0.049439\n",
       "MAR        -0.166626\n",
       "PERNP       0.791990\n",
       "NWAV        0.108792\n",
       "NWLA        0.305329\n",
       "NWLK        0.298288\n",
       "NWAB        0.292421\n",
       "SCHL        0.273946\n",
       "WKW        -0.302723\n",
       "Name: WAGP_CAT, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['WAGP_CAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c0158-2fd9-41d5-be4f-31cf6055dc3b",
   "metadata": {},
   "source": [
    "As seen from the correlation valus, column `PERNP` is highly correlated with the wage and must be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9bc177-de98-4c0d-8a0f-278b99bcb79e",
   "metadata": {},
   "source": [
    "#### **Expected output** - Columns of the dataframe after removing `PERNP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c693f88-20c5-49ca-b59a-f6a5d7f906a6",
   "metadata": {
    "cell_id": "06bfa735-d577-427e-bbff-92d6abd6b460",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WAGP_CAT', 'AGEP', 'COW', 'JWMNP', 'JWTR', 'MAR', 'NWAV', 'NWLA',\n",
      "       'NWLK', 'NWAB', 'SCHL', 'WKW'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "# YOUR CODE HERE\n",
    "# Remove the 'PERNP' column\n",
    "selected_columns.remove('PERNP')\n",
    "\n",
    "# Selecting the remaining columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Printing the columns of the selected DataFrame\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad11da-9ab4-4c3f-b894-66de77535d0a",
   "metadata": {},
   "source": [
    "#### 3.2. Dropping NAs \n",
    "\n",
    "Drop rows with any nulls in any of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60828b02-e0d4-4af3-a348-0c90b466808e",
   "metadata": {},
   "source": [
    "#### **Expected output** - Number of rows in the cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12442557-aec0-4352-ade0-06c58fd472a2",
   "metadata": {
    "cell_id": "6c341b65-4190-4afa-8e92-d665923888ed",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "# YOUR CODE HERE\n",
    "df = df.dropna()\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ed10e-ef77-40c3-ae9a-341b2c80f7cb",
   "metadata": {},
   "source": [
    "### 4. Splitting data and converting to CSV\n",
    "\n",
    "Split the dataset into train, validation, and test sets using sklearn's `train_test_split`.\n",
    "Look up the API definition of `train_test_split` to see what values you need to pass\n",
    "\n",
    "First, split the dataframe into two parts - `train_data` and `val_data` with an 70:30 ratio, and then\n",
    "split the `train_data` into `train_data` and `test_data` in a 85:15 ratio.\n",
    "\n",
    "Use the following parameters for train_test_split:\n",
    "* `random_state = 466`\n",
    "* `shuffle = True`\n",
    "* `train_size = 0.7`, `test_size = 0.3` for the first split\n",
    "* `train_size = 0.85`, `test_size = 0.15` for the second split\n",
    "\n",
    "**IMPORTANT** - Use `random_state=466` as one the parameters of the `train_test_split` function to maintain consistency across submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e2787-7532-41d3-b3d0-c740e22a2814",
   "metadata": {},
   "source": [
    "#### **Expected output** - Size of train, validation and test data in a tuple format - (length of train, length of validation, length of test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65443fc3-61c5-4ad8-92f9-3e023e30a896",
   "metadata": {
    "cell_id": "4a55c5c5-5254-4dd7-a430-daa8ab22a890",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(742813, 374529, 131085)\n"
     ]
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "random_state = 466\n",
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataframe into train_data and val_data with a 70:30 ratio\n",
    "train_data, val_data = train_test_split(df, test_size=0.3, random_state=466, shuffle=True)\n",
    "\n",
    "# Splitting the train_data into train_data and test_data with an 85:15 ratio\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.15, random_state=466, shuffle=True)\n",
    "\n",
    "# Getting the sizes of train, validation, and test data\n",
    "train_size = len(train_data)\n",
    "val_size = len(val_data)\n",
    "test_size = len(test_data)\n",
    "print((train_size, val_size, test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8642b-c685-43bf-b62f-befeb1c3b3ce",
   "metadata": {},
   "source": [
    "### Write prepared data to files.\n",
    "Write the `train_data`, `val_data`, and `test_data` to csv files using the `.to_csv()` method\n",
    "\n",
    "Use `index = False` as the parameters as shown in the demo.\n",
    "\n",
    "**NOTE:** Use `header = False` as another parameter for `train_data` and `val_data`, while for `test_data` use `header = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de7f7a9-78e8-457d-b208-95b1bce4de3d",
   "metadata": {
    "cell_id": "473f7db4-34da-4aba-9c2e-00c464b2de23",
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Write prepared data to files\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "val_data.to_csv('val_data.csv', index=False, header=False)\n",
    "test_data.to_csv('test_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87a651-c681-4a6c-8be1-6b2936eb8e5d",
   "metadata": {},
   "source": [
    "### 5. Save processed data to S3 \n",
    "\n",
    "This step is needed for using XGBoost with Amazon Sagemaker. Send data to S3. SageMaker will read training data from S3. The example for training data is given, you need do the same for validation and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14eb261-2161-4ec1-86d8-a18f375ca652",
   "metadata": {},
   "source": [
    "#### **Expected output** - Path of train, validation and test data in AWS S3 in tuple format - (train_path, val_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "353b1fe1-2534-46e9-9b5e-da0f1008f1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = 'sb-aws-bucket-mgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f14e2cd-7d12-4d0e-9b39-13d4451e4490",
   "metadata": {
    "cell_id": "d9b13f27-ce26-446e-9154-b9d13669645a",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('s3://sb-aws-bucket-mgt/data/model_data/train_data.csv', 's3://sb-aws-bucket-mgt/data/model_data/val_data.csv', 's3://sb-aws-bucket-mgt/data/model_data/test_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "\n",
    "prefix = \"data\"\n",
    "key_prefix = prefix + \"/model_data\"\n",
    "\n",
    "train_path = sess.upload_data(\n",
    "    path='train_data.csv', bucket=bucket,\n",
    "    key_prefix=key_prefix)\n",
    "\n",
    "val_path = sess.upload_data(\n",
    "    path=\"val_data.csv\", bucket=bucket, key_prefix=key_prefix)\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path=\"test_data.csv\", bucket=bucket, key_prefix=key_prefix)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print((train_path,val_path,test_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf7822-cff0-4ae5-a0d4-2201c1e2f541",
   "metadata": {},
   "source": [
    "### 6. Create channels for train and validation data to feed to model\n",
    "1. Set up data channels for the training, validation, and test data as shown in the demo\n",
    "2. Set the output location for the model\n",
    "\n",
    "You'll have to use the [`TrainingInput`](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput) function and pass the `s3_data` and `content_type` parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6f3e3-3222-4e02-8de8-502a7a836cf5",
   "metadata": {},
   "source": [
    "#### **Expected output** - [`config`](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput.config) of `TrainingInput` created for training data\n",
    "\n",
    "Refer - https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc85e109-615c-4a1f-a1e3-14d9c21bcf80",
   "metadata": {
    "cell_id": "61ac8651-8cec-47e8-b033-d55e214671df",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sb-aws-bucket-mgt/data/model_data/train_data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'csv'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_path, content_type='csv')\n",
    "s3_input_val = sagemaker.inputs.TrainingInput(s3_data=val_path, content_type='csv')\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data=test_path, content_type='csv')\n",
    "\n",
    "# Set model output location\n",
    "\n",
    "output_location = \"s3://{}/{}/model\".format(bucket,prefix)\n",
    "print((s3_input_train.config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f16e7-707c-4df6-95a5-941d45c1f0db",
   "metadata": {},
   "source": [
    "#### **Expected output** - Model's output location in AWS S3\n",
    "\n",
    "NOTE - Output format should be `s3://<bucket-name>/<path-to-model-folder>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d45caac8-351d-43f3-ab45-c1e59dda7d16",
   "metadata": {
    "cell_id": "da941cef-fcfa-4c6b-9c71-b28b5b8a42f2",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sb-aws-bucket-mgt/data/model'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98b08a-bee2-4a11-9b56-6d308ee3e647",
   "metadata": {},
   "source": [
    "### 7. Create the XGBoost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3672c680-7f4f-4980-8af5-a1adaa3fd32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE FOR XGB IMAGE\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "xgb_image = image_uris.retrieve(framework=\"xgboost\", region=my_region, version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb225f0-ed17-46f0-a14a-b10a0abdf535",
   "metadata": {},
   "source": [
    "### Create an Estimator using sagemaker.estimator.Estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f39161-6d9f-444c-a994-a73b7bbf5e0b",
   "metadata": {},
   "source": [
    "#### **Expected output** - `output_path` of the xgb Estimator. Note that this output should the same as the model output path above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94088367-4838-45e8-a669-bad81964793a",
   "metadata": {
    "cell_id": "e572123a-91aa-435e-8439-b0661002bb02",
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL\n",
    "# YOUR CODE HERE\n",
    "xgb_model = sagemaker.estimator.Estimator(xgb_image,\n",
    "                                          iam_role, \n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          output_path=output_location,\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161e16d-5ea9-4508-9ff8-e4776c79d0d3",
   "metadata": {},
   "source": [
    "### 8. Set model hyperparameters - \n",
    "Set the hyperparameters for the model. You'll have to use the `set_hyperparameters()` method.\n",
    "Refer to the demo for how it's done.\n",
    "The wages have been discretized into 3 bins so the number of classes for our classification problem is 3\n",
    "\n",
    "Read the below references for more information:\n",
    "* https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "* https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst#learning-task-parameters\n",
    "\n",
    "Use the following values for the parameters:\n",
    "* `num_class = 3`\n",
    "* `max_depth = 1`\n",
    "* `min_child_weight = 2`\n",
    "* `early_stopping_rounds=5`\n",
    "* `objective='multi:softmax'`\n",
    "* `num_round=100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3745d0a-8f6f-47dd-bf9d-9e2a4ae0226f",
   "metadata": {},
   "source": [
    "#### **Expected output** - Hyperparameters of the xgb Estimator in Python `dict` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6459e0e6-4535-4bb8-bac8-575c0f480dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.set_hyperparameters(num_class = 3,\n",
    "    max_depth = 1,\n",
    "    min_child_weight = 2,\n",
    "    early_stopping_rounds=5,\n",
    "    objective='multi:softmax',\n",
    "    num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d153ff4-ed5f-4fec-954e-b7e7e764c127",
   "metadata": {
    "cell_id": "bd0122d9-991c-4fb8-8734-d02ce355ffef",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_class': 3,\n",
       " 'max_depth': 1,\n",
       " 'min_child_weight': 2,\n",
       " 'early_stopping_rounds': 5,\n",
       " 'objective': 'multi:softmax',\n",
       " 'num_round': 100}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Hyperparameters of the xgb Estimator in Python dict format\n",
    "xgb_model.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e936f1-460d-4195-bcb3-59e331334d47",
   "metadata": {},
   "source": [
    "### Train model using train and validation data channels\n",
    "Use the `.fit()` method to fit the model using the training and validation data channels. \n",
    "Execute the XGBoost training job.\n",
    "\n",
    "NOTE:  This step may take several minutes. <br>\n",
    "Also, add parameter `logs = False` to the fit function to avoid printing extra info logs. These are different than the training logs that the fit function will automatically generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e233207-bb3c-4540-8d71-0a8354e45d84",
   "metadata": {},
   "source": [
    "#### **Expected output** - Training log. Note that you only have to call `.fit` on the xgb Estimator, with the required parameters, and the logs will  be automatically generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fff555b-09e7-4493-a55b-1aa5c1a62095",
   "metadata": {
    "cell_id": "bad95f63-5bb0-4c87-8750-e148325d623e",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2024-03-20-01-45-07-319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-20 01:45:07 Starting - Starting the training job....\n",
      "2024-03-20 01:45:36 Starting - Preparing the instances for training......\n",
      "2024-03-20 01:46:09 Downloading - Downloading input data....\n",
      "2024-03-20 01:46:34 Downloading - Downloading the training image.....\n",
      "2024-03-20 01:47:05 Training - Training image download completed. Training in progress...\n",
      "2024-03-20 01:47:20 Uploading - Uploading generated training model.\n",
      "2024-03-20 01:47:31 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_model.fit({'train': s3_input_train, 'validation': s3_input_val}, logs = False)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd293b9d-51c5-44c2-8a4f-baa8feab2e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.4540852944056195\n"
     ]
    }
   ],
   "source": [
    "print(\"Wall time:\",(end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789bd0-c792-4af0-817a-2ad999a37998",
   "metadata": {},
   "source": [
    "###  Real-time Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa09ee-0514-4cb6-a78c-6f9daa0d04f1",
   "metadata": {},
   "source": [
    "#### 10.1 Deploy endpoint for inference\n",
    "\n",
    "1. Deploy the model that you fit in the previous step as an endpoint for real-time inference\n",
    "2. Delete the endpoint after performing inference in the inference notebook\n",
    "\n",
    "Use the `.deploy()` method to deploy the model and create an endpoint for real-time inference as shown in the demo.\n",
    "\n",
    "Use the following values for the parameters:\n",
    "* `initial_instance_count = 1`\n",
    "* `serializer = sagemaker.serializers.CSVSerializer()`\n",
    "* `instance_type = 'ml.m5.xlarge'`\n",
    "\n",
    "**NOTE**:  This step may take several minutes\n",
    "\n",
    "**Go to the inference notebook to perform the inference after deploying the model in this step**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a68972-bcd3-4d1d-890d-ea251203f063",
   "metadata": {},
   "source": [
    "#### **Expected Output -** Print the name of the deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fef7ed5-0dc5-4ea4-bcd3-46ed4d47f1f1",
   "metadata": {
    "cell_id": "c84ed4ec-0fc1-4c46-b709-b178f177f381",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2024-03-20-01-47-34-585\n",
      "INFO:sagemaker:Creating endpoint-config with name xgboost-2024-03-20-01-47-34-585\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2024-03-20-01-47-34-585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'xgboost-2024-03-20-01-47-34-585'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                    instance_type='ml.m5.xlarge', serializer = sagemaker.serializers.CSVSerializer())\n",
    "model_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875f6c5-826f-422a-aa1a-16c0c2436197",
   "metadata": {},
   "source": [
    "#### 10.2 Delete endpoint \n",
    "\n",
    "**NOTE**: There is a limit on the number of active endpoints\n",
    "\n",
    "\n",
    "#### **Expected Output -** Delete endpoint logs. Note that these will be automatically generated once you delete the endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be7cccd9-3e78-45aa-b728-77c61652a90e",
   "metadata": {
    "cell_id": "efa8b8c7-03eb-448a-9a47-c7ce8c8b1e46",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: xgboost-2024-03-20-01-47-34-585\n",
      "INFO:sagemaker:Deleting endpoint with name: xgboost-2024-03-20-01-47-34-585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a79f3-9611-43f4-926b-72579b679155",
   "metadata": {},
   "source": [
    "### 16. Hyperparameter tuning \n",
    "\n",
    "Read through the following links for more information:\n",
    "* https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "* https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-automatic-model-tuning-now-supports-random-search-and-hyperparameter-scaling/\n",
    "\n",
    "We'll perform hyperparameter tuning on two hyperparameters:\n",
    "\n",
    "1. min_child_weight: 1 to 10\n",
    "2. max_depth: 2 to 10\n",
    "\n",
    "We'll use a `Random` search strategy. The code has been given for you, assuming the XGBoost estimator is stored in the variable `xgb`.\n",
    "\n",
    "`max_parallel_jobs` is set to 2 so that too many instances are not created for Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f9acde5-f978-417f-984f-6ae7cea15e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904965a-a8b4-496e-b2c8-8a17595266ae",
   "metadata": {},
   "source": [
    "Define the hyperparameters to tune in the dictionary `hyperparameter_ranges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e4529a7-6d5c-4c8b-ac75-e25dbba8fb78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_class': 3,\n",
       " 'max_depth': 1,\n",
       " 'min_child_weight': 2,\n",
       " 'early_stopping_rounds': 5,\n",
       " 'objective': 'multi:softmax',\n",
       " 'num_round': 100}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "830b6e23-5b02-4d6d-848d-cc45804a2f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth': IntegerParameter(2, 10),\n",
    "    'min_child_weight':IntegerParameter(1, 10)\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f27d74c-6c23-46c2-8e7c-2dfc5960fd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = HyperparameterTuner(\n",
    "    estimator=xgb_model,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='XGBoost-Tuner',\n",
    "    objective_type='Minimize',\n",
    "    objective_metric_name='validation:merror',\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    strategy='Random',\n",
    "    random_seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5629b-e005-4221-b8de-106c68ea9b0e",
   "metadata": {},
   "source": [
    "Now that we have created the Optimizer. We need to call `.fit()` on it to start the tuning job.\n",
    "\n",
    "Refer to the demo and see how to call `fit()` and pass the appropriate data channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233aff33-ad8e-4c8d-910d-69511040a164",
   "metadata": {},
   "source": [
    "#### **Expected output** - Tuning log. Note that you only have to call `.fit` on the optimizer, with the required parameters, and the logs will be automatically generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92cd00ac-f736-47c9-b745-8cfa493041fc",
   "metadata": {
    "cell_id": "2b55602c-bf69-4345-87bb-ec88b79679ce",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: XGBoost-Tuner-240320-0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................!\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "start_time = time.time()\n",
    "\n",
    "optimizer.fit({'train': s3_input_train, 'validation': s3_input_val}, logs = False)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03f138-2b3a-432a-9980-2ae40783d0e4",
   "metadata": {},
   "source": [
    "### 17. Best hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d0406-0b00-4279-a686-7dd60c4e4a9a",
   "metadata": {},
   "source": [
    "#### **Expected output** - Hyperparameters of the `best_estimator` of the `HyperparameterTuner` in Python's dictionary(`dict`) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cf94c1c-da1a-419e-acc4-a1816275e8b4",
   "metadata": {
    "cell_id": "cecbaf0a-b859-4593-b299-534e3e6fe894",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-20 02:15:46 Starting - Preparing the instances for training\n",
      "2024-03-20 02:15:46 Downloading - Downloading the training image\n",
      "2024-03-20 02:15:46 Training - Training image download completed. Training in progress.\n",
      "2024-03-20 02:15:46 Uploading - Uploading generated training model\n",
      "2024-03-20 02:15:46 Completed - Resource reused by training job: XGBoost-Tuner-240320-0212-004-806ca846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': 'validation:merror',\n",
       " 'early_stopping_rounds': '5',\n",
       " 'max_depth': '9',\n",
       " 'min_child_weight': '2',\n",
       " 'num_class': '3',\n",
       " 'num_round': '100',\n",
       " 'objective': 'multi:softmax'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.best_estimator().hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b4df2-67b2-4d97-b0e7-6ef673fd6b75",
   "metadata": {},
   "source": [
    "### 18. Real-time inference after Hyperparamter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1691542-9512-4e4f-8b05-0fba8a02a255",
   "metadata": {},
   "source": [
    "#### 18.1 Deploy the tuned model as an endpoint\n",
    "**NOTE**:  This step may take several minutes\n",
    "\n",
    "1. Deploy the tuned model with the best parameters that you got in the previous steps as an endpoint for real-time inference\n",
    "2. Delete the endpoint after performing inference in the inference notebook\n",
    "\n",
    "Use the `.deploy()` method to deploy the model and create an endpoint for real-time inference as shown in the demo.\n",
    "\n",
    "Use the following values for the parameters:\n",
    "* `initial_instance_count = 1`\n",
    "* `serializer = sagemaker.serializers.CSVSerializer()`\n",
    "* `instance_type = 'ml.m5.xlarge'`\n",
    "\n",
    "**NOTE**:  This step may take several minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93c42f-9a42-495f-aafb-5da1ccffd51c",
   "metadata": {},
   "source": [
    "#### **Expected Output -** Print the name of the deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f68bae70-f62c-450c-805f-f74a9f403443",
   "metadata": {
    "cell_id": "0b9ffb68-99d0-4dae-83ad-edf8fb391b18",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-20 02:15:46 Starting - Preparing the instances for training\n",
      "2024-03-20 02:15:46 Downloading - Downloading the training image\n",
      "2024-03-20 02:15:46 Training - Training image download completed. Training in progress.\n",
      "2024-03-20 02:15:46 Uploading - Uploading generated training model\n",
      "2024-03-20 02:15:46 Completed - Resource reused by training job: XGBoost-Tuner-240320-0212-004-806ca846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: XGBoost-Tuner-2024-03-20-02-22-23-756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name XGBoost-Tuner-240320-0212-002-2b47cacb\n",
      "INFO:sagemaker:Creating endpoint with name XGBoost-Tuner-240320-0212-002-2b47cacb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "tuned_model_predictor = optimizer.deploy(initial_instance_count=1,\n",
    "                    instance_type='ml.m5.xlarge', serializer = sagemaker.serializers.CSVSerializer())\n",
    "\n",
    "tuned_model_predictor.endpoint_name\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e6ae45b-e801-4231-af47-f9c3fbd3d3f1",
   "metadata": {
    "cell_id": "011a5d03-141a-460c-9f43-e1437d0c6563",
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: XGBoost-Tuner-240320-0212-002-2b47cacb\n",
      "INFO:sagemaker:Deleting endpoint with name: XGBoost-Tuner-240320-0212-002-2b47cacb\n"
     ]
    }
   ],
   "source": [
    "tuned_model_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
